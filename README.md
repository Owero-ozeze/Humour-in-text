# Humour-in-text
This research aims at developing an accurate and robust system for humour detection by developing models that are capable of accurately identifying instances of humour in text with a high degree of accuracy. We research considers three deep learning Models in this research and a simple machine learning classifier as the baseline. Firstly, two dimensions of extrinsic word embeddings, Global Vectors and FastText in conjunction with Long Short-Term Memory. Secondly, finetune state-of-art transformer models, BERT and Distillation-BERT to explore how differently these models perform. The effectiveness of the different classifiers will be evaluated using different evaluation techniques. 

RESULTS

BERT model did essentially well when viewed alongside the other models, the model had an F1-score of 97% while DistilBERT had an F1-score of 96%. LSTM also performed well with an F1-score of 94% and 95% when FastText and GloVe embeddings were used. However, LSTM did not perform as well as the other transformer models. Lastly, Naïve Bayes Classifier which is a commonly used machine learning classifier for text classification performed the lowest in this study, with an accuracy of 91%. Furthermore, each model performed effectively well when the overall performance is considered. In this research, the state-of-art model, BERT is a better classification model. However, due to its computational load, DistilBERT which is faster and lighter can be considered. 

CONCLUSION

The findings of this study provide evidence for the idea that deep learning approaches, those based on transformer architectures offer advantages over traditional machine learning methods due to their ability to learn contextual meaning of words and complex linguistic patterns. This Study’s analysis indicates that while all the techniques used were able to detect humor, the novel models performed better than the others. BERT which is a state-of-art model performed the highest with an F1-score of 97%. Furthermore, though the accuracies the models attained are significantly high, they might not accurately reflect the subtleties of humour as humour is subjective, hence in future it is necessary to increase the robustness of models to cover a range of humour styles like sarcasm, pun e.tc. Additionally, more than just the conventional metrics used in this study and some previous studies, additional information about the detection of potential biases or limitations such as misinterpretation of humour leading to false negatives and positives that might not be obvious from just the use of these quantitative metrics can be obtained from human evaluation due to the subjectivity (Weller & Seppi, 2019). 
